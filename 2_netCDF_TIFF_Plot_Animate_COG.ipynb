{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhojRajBist/BhojRajBist/blob/main/2_netCDF_TIFF_Plot_Animate_COG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22209c09-ca88-48df-88bc-5d35e96f39bf",
      "metadata": {
        "id": "22209c09-ca88-48df-88bc-5d35e96f39bf"
      },
      "source": [
        "# NCMRWF to TIFF to COG (Manual Download)\n",
        "\n",
        "This code:\n",
        "1. Convert the NetCDF to TIFF, choose best 121 hrs files, plot and animate\n",
        "2. Convert TIFF to COG"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3df16248-2417-4238-a716-999d990014d1",
      "metadata": {
        "tags": [],
        "id": "3df16248-2417-4238-a716-999d990014d1"
      },
      "source": [
        "### USER INPUT HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "root_dir = \"20240621\"\n",
        "\n",
        "# Create the directory if it does not exist\n",
        "if not os.path.exists(root_dir):\n",
        "    os.makedirs(root_dir)\n",
        "    print(f\"Directory {root_dir} created.\")\n",
        "else:\n",
        "    print(f\"Directory {root_dir} already exists.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgvYYUxcF4YH",
        "outputId": "905a3096-676a-4f5e-cbcd-411ad87c852b"
      },
      "id": "VgvYYUxcF4YH",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory 20240621 already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "147a5959-9405-4358-8a97-74925c8c44d1",
      "metadata": {
        "tags": [],
        "id": "147a5959-9405-4358-8a97-74925c8c44d1"
      },
      "outputs": [],
      "source": [
        "#Mention Root Directory\n",
        "root_dir = \"20240621\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d80c7a7c-3612-4692-b893-b8aa12a5ed74",
      "metadata": {
        "id": "d80c7a7c-3612-4692-b893-b8aa12a5ed74"
      },
      "outputs": [],
      "source": [
        "# Define the latitude and longitude bounds for Nepal (For specific region change here)\n",
        "# NCUMGLB12.5 only available for lat [26, 31] and lon [79, 89]\n",
        "\n",
        "lat_bounds = [26, 31]\n",
        "lon_bounds = [79, 89]\n",
        "\n",
        "# Set the interval time in milliseconds\n",
        "interval_time = 1000  # 1 second"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd306505-2dbf-440b-a1b3-ca4df1da733d",
      "metadata": {
        "tags": [],
        "id": "cd306505-2dbf-440b-a1b3-ca4df1da733d"
      },
      "source": [
        "### DON'T CHANGE BELOW THIS LINE\n",
        "\n",
        "just run each cell below for the objective defined by the comment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4b83048-bc61-44dc-b3d2-a3edc3b7bbad",
      "metadata": {
        "tags": [],
        "id": "d4b83048-bc61-44dc-b3d2-a3edc3b7bbad"
      },
      "source": [
        "#### STEP- 0: Initialization (Libraries, pacakages and inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "cab5886a-ec74-4308-89d9-f52981e90264",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cab5886a-ec74-4308-89d9-f52981e90264",
        "outputId": "a4c83942-5327-41b5-ec09-9d135c89d947"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.7.1.post1)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2024.6.0)\n",
            "Requirement already satisfied: rasterio in /usr/local/lib/python3.10/dist-packages (1.3.10)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2024.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.25.2)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from xarray) (24.1)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from xarray) (2.0.3)\n",
            "Requirement already satisfied: affine in /usr/local/lib/python3.10/dist-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: snuggs>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.4.7)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->xarray) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->xarray) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->xarray) (2024.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->xarray) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install netCDF4 xarray rasterio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cartopy xarray netCDF4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JySv6hPF-xID",
        "outputId": "c583e909-1685-4040-a491-e7bc47bafd4f"
      },
      "id": "JySv6hPF-xID",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: cartopy in /usr/local/lib/python3.10/dist-packages (0.23.0)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.10/dist-packages (2024.6.0)\n",
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.7.1.post1)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from cartopy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.7.1)\n",
            "Requirement already satisfied: shapely>=1.7 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.0.4)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from cartopy) (24.1)\n",
            "Requirement already satisfied: pyshp>=2.3 in /usr/local/lib/python3.10/dist-packages (from cartopy) (2.3.1)\n",
            "Requirement already satisfied: pyproj>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from cartopy) (3.6.1)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from xarray) (2.0.3)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2024.6.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.5->cartopy) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->xarray) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->xarray) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.5->cartopy) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "f1636fe9-1fb8-4e48-ac68-fc06c36cb815",
      "metadata": {
        "tags": [],
        "id": "f1636fe9-1fb8-4e48-ac68-fc06c36cb815"
      },
      "outputs": [],
      "source": [
        "# Import necessary packages\n",
        "import os\n",
        "from datetime import datetime\n",
        "import ftplib\n",
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xarray as xr\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import cartopy.crs as ccrs\n",
        "import cartopy.feature as cfeature\n",
        "import imageio\n",
        "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
        "from IPython.display import HTML\n",
        "import rasterio\n",
        "from rasterio.transform import from_origin\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "from rasterio.crs import CRS\n",
        "from pyproj import CRS\n",
        "from osgeo import gdal\n",
        "import shutil\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "3356cc91-206b-4fc3-9098-4907e31a043a",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3356cc91-206b-4fc3-9098-4907e31a043a",
        "outputId": "f060832a-c28f-401c-9fbb-3b7210d9e1d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root directory: 20240621\n",
            "Generated file name: APCP_3hourly_ncum_reg_20240621_00Z.nc\n",
            "Generated file path: 20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc\n",
            "Generated file name1: ncumglb_prg_26-31N_79-89E_0.125x0.125_20240621_00Z.nc\n",
            "Generated file path1: 20240621/ncumglb_prg_26-31N_79-89E_0.125x0.125_20240621_00Z.nc\n",
            "Contents of 20240621: ['ncumglb_prg_26-31N_79-89E_0.125x0.125_20240621_00Z.nc', 'TIFF_Files', 'APCP_3hourly_ncum_reg_20240621_00Z.nc', 'COG_Files']\n",
            "File successfully created: 20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc\n",
            "File successfully created: 20240621/ncumglb_prg_26-31N_79-89E_0.125x0.125_20240621_00Z.nc\n",
            "Contents of 20240621 after writing files: ['ncumglb_prg_26-31N_79-89E_0.125x0.125_20240621_00Z.nc', 'TIFF_Files', 'APCP_3hourly_ncum_reg_20240621_00Z.nc', 'COG_Files']\n"
          ]
        }
      ],
      "source": [
        "# # File Name and Path being generated\n",
        "# file_name = f\"APCP_3hourly_ncum_reg_{root_dir}_00Z.nc\"\n",
        "# file_name1 = f\"ncumglb_prg_26-31N_79-89E_0.125x0.125_{root_dir}_00Z.nc\"\n",
        "\n",
        "# # Construct the file path\n",
        "# file_path = os.path.join(root_dir, file_name)\n",
        "# file_path1 = os.path.join(root_dir, file_name1)\n",
        "\n",
        "# print(f\"File path: {file_path}\")\n",
        "# print(f\"File path: {file_path1}\")\n",
        "\n",
        "import os\n",
        "\n",
        "# Define root directory\n",
        "root_dir = \"20240621\"\n",
        "\n",
        "# Ensure the root directory exists\n",
        "if not os.path.exists(root_dir):\n",
        "    os.makedirs(root_dir)\n",
        "\n",
        "# Generate file names\n",
        "file_name = f\"APCP_3hourly_ncum_reg_{root_dir}_00Z.nc\"\n",
        "file_name1 = f\"ncumglb_prg_26-31N_79-89E_0.125x0.125_{root_dir}_00Z.nc\"\n",
        "\n",
        "# Construct the file paths\n",
        "file_path = os.path.join(root_dir, file_name)\n",
        "file_path1 = os.path.join(root_dir, file_name1)\n",
        "\n",
        "# Debugging outputs\n",
        "print(f\"Root directory: {root_dir}\")\n",
        "print(f\"Generated file name: {file_name}\")\n",
        "print(f\"Generated file path: {file_path}\")\n",
        "print(f\"Generated file name1: {file_name1}\")\n",
        "print(f\"Generated file path1: {file_path1}\")\n",
        "\n",
        "# Check if directory exists\n",
        "if not os.path.exists(root_dir):\n",
        "    print(f\"Directory does not exist: {root_dir}\")\n",
        "else:\n",
        "    # List directory contents\n",
        "    print(f\"Contents of {root_dir}: {os.listdir(root_dir)}\")\n",
        "\n",
        "    # Verify file existence\n",
        "    if not os.path.exists(file_path):\n",
        "        print(f\"File not found: {file_path}\")\n",
        "    if not os.path.exists(file_path1):\n",
        "        print(f\"File not found: {file_path1}\")\n",
        "\n",
        "    # Ensure files are written\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write('Actual content for APCP_3hourly_ncum_reg')\n",
        "    with open(file_path1, 'w') as f:\n",
        "        f.write('Actual content for ncumglb_prg')\n",
        "\n",
        "    # Verify file creation\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"File successfully created: {file_path}\")\n",
        "    if os.path.exists(file_path1):\n",
        "        print(f\"File successfully created: {file_path1}\")\n",
        "\n",
        "    print(f\"Contents of {root_dir} after writing files: {os.listdir(root_dir)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install netCDF4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9qzv90XO9A_",
        "outputId": "c22a8276-bd76-43ba-bbb9-b76ede170b93"
      },
      "id": "v9qzv90XO9A_",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.10/dist-packages (1.7.1.post1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.6.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from netCDF4) (2024.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from netCDF4) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8af4267f-82d8-4fc7-bd19-b9a23037489f",
      "metadata": {
        "tags": [],
        "id": "8af4267f-82d8-4fc7-bd19-b9a23037489f"
      },
      "source": [
        "#### STEP-1: Convert Netcdf to TIFF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "378a63e1-6c7e-4d22-be9a-e46e7ef19620",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "378a63e1-6c7e-4d22-be9a-e46e7ef19620",
        "outputId": "ce6c82fe-45cc-47ca-f13e-e193ffbde165"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists: /content/20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc\n",
            "File size: 40 bytes\n",
            "Error opening NetCDF file: [Errno -51] NetCDF: Unknown file format: '/content/20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno -51] NetCDF: Unknown file format: '/content/20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/lru_cache.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_to_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/content/20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc',), 'r', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), 'fd98e431-a417-4153-b3e4-a908a9b17f80']",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-f6a1fc4c59ba>\u001b[0m in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;31m# Step-1: Generate TIFF files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m \u001b[0mtiff_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_netcdf_to_tiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'4KM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0mtiff_files1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclip_netcdf_to_tiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'12.5KM'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-43-f6a1fc4c59ba>\u001b[0m in \u001b[0;36mclip_netcdf_to_tiff\u001b[0;34m(file_path, resolution)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Open the NetCDF dataset with a specified engine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'netcdf4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;31m# Subset the dataset to the specified region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0moverwrite_encoded_chunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overwrite_encoded_chunks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m     backend_ds = backend.open_dataset(\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mdrop_variables\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop_variables\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(self, filename_or_obj, mask_and_scale, decode_times, concat_characters, decode_coords, drop_variables, use_cftime, decode_timedelta, group, mode, format, clobber, diskless, persist, lock, autoclose)\u001b[0m\n\u001b[1;32m    643\u001b[0m     ) -> Dataset:\n\u001b[1;32m    644\u001b[0m         \u001b[0mfilename_or_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         store = NetCDF4DataStore.open(\n\u001b[0m\u001b[1;32m    646\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mnetCDF4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         )\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautoclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_remote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_remote_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen_store_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_acquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m             \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_nc4_require_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36macquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0macquire_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneeds_lock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;34m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcached\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_acquire_with_cache_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneeds_lock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/xarray/backends/file_manager.py\u001b[0m in \u001b[0;36m_acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m                     \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                     \u001b[0;31m# ensure file doesn't get overridden when opened again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32msrc/netCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno -51] NetCDF: Unknown file format: '/content/20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc'"
          ]
        }
      ],
      "source": [
        "# # Function to download and clip NetCDF data to TIFF\n",
        "# def clip_netcdf_to_tiff(file_path, resolution):\n",
        "#     # Extract the forecast origin string from the file path\n",
        "#     filename = os.path.basename(file_path)\n",
        "\n",
        "#     # Assuming the forecast origin date is in the filename in the format YYYYMMDD\n",
        "#     forecast_origin_str = filename.split('_')[-2]\n",
        "#     forecast_origin = datetime.strptime(forecast_origin_str, \"%Y%m%d\")\n",
        "\n",
        "#     # Open the NetCDF dataset\n",
        "#     dataset = xr.open_dataset(file_path)\n",
        "\n",
        "#     # Subset the dataset to the specified region\n",
        "#     subset_dataset = dataset.sel(lat=slice(lat_bounds[0], lat_bounds[1]), lon=slice(lon_bounds[0], lon_bounds[1]))\n",
        "\n",
        "#     # Create the output directory if it doesn't exist\n",
        "#     output_dir_tiff = os.path.join(root_dir, \"TIFF_Files_\"+resolution)\n",
        "#     os.makedirs(output_dir_tiff, exist_ok=True)\n",
        "\n",
        "#     # List to store file paths\n",
        "#     tiff_file_paths = []\n",
        "\n",
        "#     # Define the CRS for the output raster\n",
        "#     output_crs = CRS.from_epsg(4326)  # WGS 1984\n",
        "\n",
        "#     # Loop through each time step in the dataset\n",
        "#     for i, time_step in enumerate(subset_dataset['time']):\n",
        "#         # Get the data array for the current time step\n",
        "#         data_array = subset_dataset['param8.1.0'].isel(time=i).values\n",
        "\n",
        "#         # Get the time string for the current time step\n",
        "#         time_string = str(time_step.values)[:-10]  # Exclude milliseconds\n",
        "#         time_format = \"%Y-%m-%dT%H:%M:%S\"\n",
        "#         time_obj = datetime.strptime(time_string, time_format)\n",
        "\n",
        "#         # Calculate the timestep in hours\n",
        "#         timestep_hours = int((time_obj - forecast_origin).total_seconds() / 3600)\n",
        "#         timestep_str = f\"{timestep_hours:03d}\"  # Format as three digits\n",
        "\n",
        "#         # Calculate the forecast hour index (incrementing integer starting from 00)\n",
        "#         forecast_hour_index = i + 1\n",
        "#         forecast_hour_index_str = f\"{forecast_hour_index:02d}\"  # Format as two digits\n",
        "\n",
        "#         # Set the output file name\n",
        "#         output_name = f'NCMRWF_Nepal_{time_obj.strftime(\"%Y%m%d%H\")}F{forecast_hour_index_str}O{forecast_origin_str}00H{timestep_str}R{resolution}.tif'\n",
        "\n",
        "#         # Get the GeoTransform\n",
        "#         transform = from_origin(lon_bounds[0], lat_bounds[0], subset_dataset.lon.values[1] - subset_dataset.lon.values[0], subset_dataset.lat.values[0] - subset_dataset.lat.values[1])\n",
        "\n",
        "#         # Set the output file path\n",
        "#         output_file = os.path.join(output_dir_tiff, output_name)\n",
        "\n",
        "#         # Write the data array to the output TIFF file\n",
        "#         with rasterio.open(output_file, 'w', driver='GTiff', count=1, dtype='float32', crs=output_crs, transform=transform, width=data_array.shape[1], height=data_array.shape[0]) as dst:\n",
        "#             dst.write(data_array, 1)\n",
        "\n",
        "#         # Append the output file path to the list\n",
        "#         tiff_file_paths.append(output_file)\n",
        "\n",
        "#     print(\"TIFF files generated and saved successfully.\")\n",
        "\n",
        "#     # Return the list of file paths\n",
        "#     return tiff_file_paths\n",
        "\n",
        "# # step-1: Generate TIFF files\n",
        "# tiff_files = clip_netcdf_\n",
        "# Define root directory\n",
        "# root_dir = \"20240621\"to_tiff(file_path, '4KM')\n",
        "# tiff_files1 = clip_netcdf_to_tiff(file_path1, '12.5KM')\n",
        "\n",
        "# # Print TIFF files to verify\n",
        "# print(\"TIFF files generated for APCP 4 km:\", tiff_files)\n",
        "# print(\"TIFF files generated for NCUMGLB 12.5 km:\", tiff_files1)\n",
        "\n",
        "import os\n",
        "import xarray as xr\n",
        "from datetime import datetime\n",
        "from pyproj import CRS\n",
        "from rasterio.transform import from_origin\n",
        "import rasterio\n",
        "\n",
        "\n",
        "\n",
        "# Assuming lat_bounds and lon_bounds are defined\n",
        "lat_bounds = [26.0, 30.0]\n",
        "lon_bounds = [80.0, 88.0]\n",
        "\n",
        "import os\n",
        "\n",
        "file_path = '/content/20240621/APCP_3hourly_ncum_reg_20240621_00Z.nc'\n",
        "\n",
        "if os.path.exists(file_path):\n",
        "    print(f\"File exists: {file_path}\")\n",
        "\n",
        "    # Check file size\n",
        "    file_size = os.path.getsize(file_path)\n",
        "    print(f\"File size: {file_size} bytes\")\n",
        "\n",
        "    # Try to open the file using netCDF4 directly\n",
        "    try:\n",
        "        from netCDF4 import Dataset\n",
        "        nc_file = Dataset(file_path, 'r')\n",
        "        print(f\"Opened file: {file_path}\")\n",
        "        print(f\"File dimensions: {nc_file.dimensions.keys()}\")\n",
        "        print(f\"File variables: {nc_file.variables.keys()}\")\n",
        "        nc_file.close()\n",
        "    except Exception as e:\n",
        "        print(f\"Error opening NetCDF file: {e}\")\n",
        "else:\n",
        "    print(f\"File does not exist: {file_path}\")\n",
        "\n",
        "\n",
        "# Function to download and clip NetCDF data to TIFF\n",
        "def clip_netcdf_to_tiff(file_path, resolution):\n",
        "    # Extract the forecast origin string from the file path\n",
        "    filename = os.path.basename(file_path)\n",
        "\n",
        "    # Assuming the forecast origin date is in the filename in the format YYYYMMDD\n",
        "    forecast_origin_str = filename.split('_')[-2]\n",
        "    forecast_origin = datetime.strptime(forecast_origin_str, \"%Y%m%d\")\n",
        "\n",
        "    # Open the NetCDF dataset with a specified engine\n",
        "    dataset = xr.open_dataset(file_path, engine='netcdf4')\n",
        "\n",
        "    # Subset the dataset to the specified region\n",
        "    subset_dataset = dataset.sel(lat=slice(lat_bounds[0], lat_bounds[1]), lon=slice(lon_bounds[0], lon_bounds[1]))\n",
        "\n",
        "    # Create the output directory if it doesn't exist\n",
        "    output_dir_tiff = os.path.join(root_dir, \"TIFF_Files_\" + resolution)\n",
        "    os.makedirs(output_dir_tiff, exist_ok=True)\n",
        "\n",
        "    # List to store file paths\n",
        "    tiff_file_paths = []\n",
        "\n",
        "    # Define the CRS for the output raster\n",
        "    output_crs = CRS.from_epsg(4326)  # WGS 1984\n",
        "\n",
        "    # Loop through each time step in the dataset\n",
        "    for i, time_step in enumerate(subset_dataset['time']):\n",
        "        # Get the data array for the current time step\n",
        "        data_array = subset_dataset['param8.1.0'].isel(time=i).values\n",
        "\n",
        "        # Get the time string for the current time step\n",
        "        time_string = str(time_step.values)[:-10]  # Exclude milliseconds\n",
        "        time_format = \"%Y-%m-%dT%H:%M:%S\"\n",
        "        time_obj = datetime.strptime(time_string, time_format)\n",
        "\n",
        "        # Calculate the timestep in hours\n",
        "        timestep_hours = int((time_obj - forecast_origin).total_seconds() / 3600)\n",
        "        timestep_str = f\"{timestep_hours:03d}\"  # Format as three digits\n",
        "\n",
        "        # Calculate the forecast hour index (incrementing integer starting from 00)\n",
        "        forecast_hour_index = i + 1\n",
        "        forecast_hour_index_str = f\"{forecast_hour_index:02d}\"  # Format as two digits\n",
        "\n",
        "        # Set the output file name\n",
        "        output_name = f'NCMRWF_Nepal_{time_obj.strftime(\"%Y%m%d%H\")}F{forecast_hour_index_str}O{forecast_origin_str}00H{timestep_str}R{resolution}.tif'\n",
        "\n",
        "        # Get the GeoTransform\n",
        "        transform = from_origin(lon_bounds[0], lat_bounds[1], subset_dataset.lon.values[1] - subset_dataset.lon.values[0], subset_dataset.lat.values[0] - subset_dataset.lat.values[1])\n",
        "\n",
        "        # Set the output file path\n",
        "        output_file = os.path.join(output_dir_tiff, output_name)\n",
        "\n",
        "        # Write the data array to the output TIFF file\n",
        "        with rasterio.open(output_file, 'w', driver='GTiff', count=1, dtype='float32', crs=output_crs, transform=transform, width=data_array.shape[1], height=data_array.shape[0]) as dst:\n",
        "            dst.write(data_array, 1)\n",
        "\n",
        "        # Append the output file path to the list\n",
        "        tiff_file_paths.append(output_file)\n",
        "\n",
        "    print(\"TIFF files generated and saved successfully.\")\n",
        "\n",
        "    # Return the list of file paths\n",
        "    return tiff_file_paths\n",
        "\n",
        "# Step-1: Generate TIFF files\n",
        "tiff_files = clip_netcdf_to_tiff(file_path, '4KM')\n",
        "tiff_files1 = clip_netcdf_to_tiff(file_path1, '12.5KM')\n",
        "\n",
        "# Print TIFF files to verify\n",
        "print(\"TIFF files generated for APCP 4 km:\", tiff_files)\n",
        "print(\"TIFF files generated for NCUMGLB 12.5 km:\", tiff_files1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "dae05b68-2513-4a1b-9fca-0f6e4917e6bb",
      "metadata": {
        "tags": [],
        "id": "dae05b68-2513-4a1b-9fca-0f6e4917e6bb",
        "outputId": "cbccc94d-064b-44ee-b21c-725db1c37734",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '20240621/TIFF_Files_4KM'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-fae88922fc64>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Step 1: Copy all files from cog_tiff_files_4km\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mcopy_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtiff_files_4km\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTIFF_120Hrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Step 2: Copy only the required files from cog_tiff_files_12_5km\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-fae88922fc64>\u001b[0m in \u001b[0;36mcopy_files\u001b[0;34m(src_dir, dst_dir, forecast_threshold)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0msrc_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '20240621/TIFF_Files_4KM'"
          ]
        }
      ],
      "source": [
        "#Function to combine both the forecast: upto 75 HRS 4Km resolution and upto 121 HRS 12.5Km resolution\n",
        "def copy_files(src_dir, dst_dir, forecast_threshold=None):\n",
        "    \"\"\"\n",
        "    Copies files from src_dir to dst_dir.\n",
        "    If forecast_threshold is specified, only copies files with a forecast index >= forecast_threshold.\n",
        "    \"\"\"\n",
        "    os.makedirs(dst_dir, exist_ok=True)\n",
        "\n",
        "    for filename in os.listdir(src_dir):\n",
        "        src_file = os.path.join(src_dir, filename)\n",
        "\n",
        "        if os.path.isfile(src_file):\n",
        "            if forecast_threshold:\n",
        "                # Extract the forecast index from the filename\n",
        "                match = re.search(r'F(\\d+)', filename)\n",
        "                if match and int(match.group(1)) >= forecast_threshold:\n",
        "                    shutil.copy2(src_file, dst_dir)\n",
        "            else:\n",
        "                shutil.copy2(src_file, dst_dir)\n",
        "\n",
        "# Paths to the source directories\n",
        "tiff_files_4km = f'{root_dir}/TIFF_Files_4KM'\n",
        "tiff_files_12_5km = f'{root_dir}/TIFF_Files_12.5KM'\n",
        "\n",
        "# Path to the destination directory\n",
        "TIFF_120Hrs = f'{root_dir}/TIFF_Files'\n",
        "\n",
        "# Step 1: Copy all files from cog_tiff_files_4km\n",
        "copy_files(tiff_files_4km, TIFF_120Hrs)\n",
        "\n",
        "# Step 2: Copy only the required files from cog_tiff_files_12_5km\n",
        "copy_files(tiff_files_12_5km, TIFF_120Hrs, forecast_threshold=26)\n",
        "\n",
        "# Verify the contents of the new directory\n",
        "dst_contents = os.listdir(TIFF_120Hrs)\n",
        "print(\"Contents of the new directory:\", dst_contents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f22e141-09bc-4f75-9012-e534adb5505c",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9f22e141-09bc-4f75-9012-e534adb5505c",
        "outputId": "b663291a-4f1d-443d-94b1-9a0b50bdb4ad"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'TIFF_120Hrs' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-26540d109468>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# Call the function to plot precipitation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m \u001b[0mplot_precipitation_data_tiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTIFF_120Hrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'TIFF_120Hrs' is not defined"
          ]
        }
      ],
      "source": [
        "# Function to plot precipitation data over Nepal from TIFF files\n",
        "def plot_precipitation_data_tiff(directory):\n",
        "    # Get a list of all TIFF files in the directory\n",
        "    tiff_files = [f for f in os.listdir(directory) if f.endswith('.tif')]\n",
        "\n",
        "    # Define the number of columns and calculate the number of rows\n",
        "    num_columns = 6\n",
        "    num_plots = len(tiff_files)\n",
        "    num_rows = -(-num_plots // num_columns)  # Ceiling division to ensure all images are displayed\n",
        "\n",
        "    # Set the base figure size to fit an A3 paper while maintaining aspect ratio\n",
        "    base_fig_size = 11  # Adjust this value to fit within A3 landscape dimensions 42.0 cm (16.53 inches) width x 29.7 cm (11.69 inches) heigh\n",
        "    fig_width = 12 * num_columns\n",
        "    fig_height = 6 * num_rows\n",
        "\n",
        "    # Ensure the figure size fits within estimated size\n",
        "    max_fig_width = 84\n",
        "    max_fig_height = 58\n",
        "\n",
        "    if fig_width > max_fig_width:\n",
        "        scaling_factor = max_fig_width / fig_width\n",
        "        fig_width *= scaling_factor\n",
        "\n",
        "\n",
        "    if fig_height > max_fig_height:\n",
        "        scaling_factor = max_fig_height / fig_height\n",
        "        fig_height *= scaling_factor\n",
        "\n",
        "    # Create subplots with constrained layout\n",
        "    fig, axes = plt.subplots(num_rows, num_columns, figsize=(fig_width, fig_height), subplot_kw={'projection': ccrs.PlateCarree()}, constrained_layout=True)\n",
        "\n",
        "    # Flatten the axes array for easy iteration\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Plot each TIFF file\n",
        "    for i, tiff_file in enumerate(tiff_files):\n",
        "        file_path = os.path.join(directory, tiff_file)\n",
        "        with rasterio.open(file_path) as src:\n",
        "            precipitation = src.read(1)\n",
        "            bounds = src.bounds\n",
        "\n",
        "            ax = axes[i]\n",
        "            ax.set_extent([lon_bounds[0], lon_bounds[1], lat_bounds[0], lat_bounds[1]], crs=ccrs.PlateCarree())\n",
        "            ax.add_feature(cfeature.BORDERS.with_scale('10m'), linestyle='-', linewidth=1, edgecolor='red')\n",
        "            ax.add_feature(cfeature.RIVERS)\n",
        "\n",
        "            # Define the extent explicitly using bounds\n",
        "            im = ax.imshow(precipitation, cmap='viridis', extent=[bounds.left, bounds.right, bounds.bottom, bounds.top], transform=ccrs.PlateCarree(), vmin=0, vmax=100)\n",
        "\n",
        "            # Set the title with the file name\n",
        "            filename = f'{tiff_file}'\n",
        "\n",
        "            # Split the filename by underscores to get parts\n",
        "            parts = filename.split('_')\n",
        "\n",
        "            # Extract the timestamp part and remove any additional characters\n",
        "            timestamp = parts[2].split('F')[0]  # 'F' is the separator\n",
        "\n",
        "            # Extract the forecast index part and remove any additional characters\n",
        "            forecastIndex = parts[2].split('F')[1].split('O')[0]  # 'F' is the separator\n",
        "\n",
        "            # Extract the forecast hours part and remove any additional characters\n",
        "            forecastHrsPart = parts[2].split('H')[1]  # 'H' is the separator\n",
        "            forecastHrs = forecastHrsPart.split('R')[0]  # 'H' is the separator\n",
        "\n",
        "            # Use the extracted timestamp and forecast hours as tile\n",
        "            title = timestamp + 'UTC-F' + forecastIndex + 'H' +forecastHrs\n",
        "\n",
        "            ax.set_title(title, fontsize=28)\n",
        "\n",
        "            # Set up gridlines\n",
        "            gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
        "            gl.top_labels = False  # Hide top labels\n",
        "            gl.right_labels = False  # Hide right labels\n",
        "            gl.xformatter = LongitudeFormatter\n",
        "            gl.yformatter = LatitudeFormatter\n",
        "            gl.xlabel_style = {'size': 21}\n",
        "            gl.ylabel_style = {'size': 21}\n",
        "\n",
        "            # Extract longitude and latitude values for gridlines\n",
        "            lon_ticks = np.arange(lon_bounds[0], lon_bounds[1] + 1, 2)\n",
        "            lat_ticks = np.arange(lat_bounds[0], lat_bounds[1] + 1, 2)\n",
        "\n",
        "            # Set gridline locations\n",
        "            gl.xlocator = plt.FixedLocator(lon_ticks)\n",
        "            gl.ylocator = plt.FixedLocator(lat_ticks)\n",
        "\n",
        "    # Remove any empty subplots\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    # Set a common title for all subplots\n",
        "    fig.suptitle(f\"Precipitation Over Nepal (NCMRWF) as forecasted on {root_dir} for 5 Days\", fontsize=40)\n",
        "\n",
        "    # Add a single colorbar for all plots and create a color bar with range 0 to 100\n",
        "    norm = mcolors.Normalize(vmin=0, vmax=100)\n",
        "    cbar = fig.colorbar(im, ax=axes, orientation='vertical', pad=0.02, fraction=0.025, norm=norm, location='right')\n",
        "    cbar.set_label('Precipitation (mm)', fontsize=36)\n",
        "    cbar.ax.yaxis.set_tick_params(labelsize=28)  # Adjust font size of color bar values\n",
        "\n",
        "    # Save the figure\n",
        "    plot_filename = os.path.join(root_dir, f'{root_dir} Precipitation Plot.png')\n",
        "    plt.savefig(plot_filename, bbox_inches='tight', dpi=600)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot precipitation data\n",
        "plot_precipitation_data_tiff(TIFF_120Hrs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "141fec2a-4de0-46ce-8a12-aae8470c35f9",
      "metadata": {
        "id": "141fec2a-4de0-46ce-8a12-aae8470c35f9"
      },
      "outputs": [],
      "source": [
        "# Directory to save frames\n",
        "frames_dir = os.path.join(root_dir, \"FRAMES\")\n",
        "os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "# Function to plot precipitation data over Nepal from TIFF files\n",
        "def animate_precipitation_data_tiff(directory):\n",
        "    # Get a list of all TIFF files in the directory\n",
        "    tiff_files = [f for f in os.listdir(directory) if f.endswith('.tif')]\n",
        "\n",
        "    # Plot each TIFF file\n",
        "    for i, tiff_file in enumerate(tiff_files):\n",
        "        file_path = os.path.join(directory, tiff_file)\n",
        "        with rasterio.open(file_path) as src:\n",
        "            precipitation = src.read(1)\n",
        "            bounds = src.bounds\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
        "            ax.set_extent([lon_bounds[0], lon_bounds[1], lat_bounds[0], lat_bounds[1]], crs=ccrs.PlateCarree())\n",
        "            ax.add_feature(cfeature.BORDERS.with_scale('10m'), linestyle='-', linewidth=1, edgecolor='red')\n",
        "            ax.add_feature(cfeature.RIVERS)\n",
        "\n",
        "            # Define the extent explicitly using bounds\n",
        "            im = ax.imshow(precipitation, cmap='viridis', extent=[bounds.left, bounds.right, bounds.bottom, bounds.top], transform=ccrs.PlateCarree(), vmin=0, vmax=100)\n",
        "\n",
        "            # Set the title with the file name\n",
        "            filename = f'{tiff_file}'\n",
        "\n",
        "            # Split the filename by underscores to get parts\n",
        "            parts = filename.split('_')\n",
        "\n",
        "            # Extract the timestamp part and remove any additional characters\n",
        "            timestamp = parts[2].split('F')[0]  # 'F' is the separator\n",
        "\n",
        "            # Extract the forecast index part and remove any additional characters\n",
        "            forecastIndex = parts[2].split('F')[1].split('O')[0]  # 'F' is the separator\n",
        "\n",
        "            # Extract the forecast hours part and remove any additional characters\n",
        "            forecastHrsPart = parts[2].split('H')[1]  # 'H' is the separator\n",
        "            forecastHrs = forecastHrsPart.split('R')[0]  # 'H' is the separator\n",
        "\n",
        "            # Use the extracted timestamp and forecast hours as tile\n",
        "            title = timestamp + 'UTC-F' + forecastIndex + 'H' +forecastHrs\n",
        "\n",
        "            ax.set_title(title, fontsize=18, pad=30)\n",
        "\n",
        "            # Set up gridlines\n",
        "            gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True, linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
        "            gl.top_labels = False  # Hide top labels\n",
        "            gl.right_labels = False  # Hide right labels\n",
        "            gl.xformatter = LongitudeFormatter()\n",
        "            gl.yformatter = LatitudeFormatter()\n",
        "            gl.xlabel_style = {'size': 14}\n",
        "            gl.ylabel_style = {'size': 14}\n",
        "\n",
        "            # Extract longitude and latitude values for gridlines\n",
        "            lon_ticks = np.arange(lon_bounds[0], lon_bounds[1] + 1, 2)\n",
        "            lat_ticks = np.arange(lat_bounds[0], lat_bounds[1] + 1, 2)\n",
        "\n",
        "            # Set gridline locations\n",
        "            gl.xlocator = plt.FixedLocator(lon_ticks)\n",
        "            gl.ylocator = plt.FixedLocator(lat_ticks)\n",
        "\n",
        "            # Set a common title for all subplots\n",
        "            fig.suptitle(f\"Precipitation Over Nepal (NCMRWF) as forecasted on {root_dir}\", fontsize=20, y=0.90)\n",
        "\n",
        "            # Add a single colorbar for the plot and create a color bar with range 0 to 100\n",
        "            norm = mcolors.Normalize(vmin=0, vmax=100)\n",
        "            cbar = fig.colorbar(im, ax=ax, orientation='vertical', pad=0.07, fraction=0.025, norm=norm, location='right')\n",
        "            cbar.set_label('Precipitation (mm)', fontsize=14)\n",
        "            cbar.ax.yaxis.set_tick_params(labelsize=12)  # Adjust font size of color bar values\n",
        "\n",
        "            # Save each frame\n",
        "            frame_filename = os.path.join(frames_dir, f'frame_{i:04d}.png')\n",
        "            plt.savefig(frame_filename, bbox_inches='tight', dpi=400)\n",
        "            plt.close(fig)\n",
        "\n",
        "    print(\"Frames saved successfully.\")\n",
        "\n",
        "     # Create an animated GIF from the frames with a delay between frames\n",
        "    frame_files = sorted([os.path.join(frames_dir, f) for f in os.listdir(frames_dir) if f.endswith('.png')])\n",
        "    gif_filename = os.path.join(root_dir, f'precipitation_animation_{root_dir}.gif')\n",
        "    with imageio.get_writer(gif_filename, mode='I', duration=1) as writer:  # 1-second delay\n",
        "        for frame_file in frame_files:\n",
        "            image = imageio.v2.imread(frame_file)\n",
        "            writer.append_data(image)\n",
        "\n",
        "    print(f\"Animation saved as {gif_filename}.\")\n",
        "\n",
        "    # Function to update each frame\n",
        "    def update(frame):\n",
        "        im.set_data(plt.imread(frame_files[frame]))\n",
        "        return im,\n",
        "\n",
        "    # Create a figure without the outer frame\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "    ax.axis('off')  # Turn off the axis\n",
        "\n",
        "    # Display the first frame\n",
        "    im = ax.imshow(plt.imread(frame_files[0]))\n",
        "\n",
        "    # Create the animation with the specified interval\n",
        "    ani = FuncAnimation(fig, update, frames=len(frame_files), interval=interval_time)\n",
        "\n",
        "    # Display the animation\n",
        "    return HTML(ani.to_html5_video())\n",
        "\n",
        "# Call the function to plot precipitation data\n",
        "animate_precipitation_data_tiff(TIFF_120Hrs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58a6c80-48c4-4a67-9f2c-83fa41628e05",
      "metadata": {
        "id": "c58a6c80-48c4-4a67-9f2c-83fa41628e05"
      },
      "source": [
        "#### STEP-2: Convert Tiff to COG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "bd995af3-fb28-48ae-a9c8-e468ea49f8a0",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bd995af3-fb28-48ae-a9c8-e468ea49f8a0",
        "outputId": "c0f52e20-b9e1-4d16-af73-cdb3707b3127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TIFF files generated: []\n",
            "No TIFF files provided for conversion.\n",
            "Cloud Optimized GeoTIFFs files generated: []\n"
          ]
        }
      ],
      "source": [
        "# Get all TIFF files in the directory\n",
        "tiff_files = [os.path.join(TIFF_120Hrs, f) for f in os.listdir(TIFF_120Hrs) if f.endswith('.tif')]\n",
        "\n",
        "# Print the list of TIFF files\n",
        "print(f\"TIFF files generated: {tiff_files}\")\n",
        "\n",
        "# Function to convert TIFF to COG TIFF\n",
        "def tiff_to_cogtiff(tiff_file_paths):\n",
        "    # Create the output directory if it doesn't exist\n",
        "    output_dir_cog = os.path.join(root_dir, \"COG_Files\")\n",
        "    os.makedirs(output_dir_cog, exist_ok=True)\n",
        "\n",
        "    # List to store COG file paths\n",
        "    cog_file_paths = []\n",
        "\n",
        "    if not tiff_file_paths:\n",
        "        print(\"No TIFF files provided for conversion.\")\n",
        "        return cog_file_paths\n",
        "\n",
        "    for tiff_file in tiff_file_paths:\n",
        "        # Set the COG output file path\n",
        "        cog_output_file = os.path.join(output_dir_cog, os.path.basename(tiff_file).replace('.tif', 'C.tif'))\n",
        "\n",
        "        # Print debug information\n",
        "        print(f\"Converting {tiff_file} to {cog_output_file}\")\n",
        "\n",
        "        # Convert the TIFF to Cloud Optimized GeoTIFF\n",
        "        try:\n",
        "            result = subprocess.run(\n",
        "                ['gdal_translate', tiff_file, cog_output_file, '-co', 'TILED=YES', '-co', 'COPY_SRC_OVERVIEWS=YES', '-co', 'COMPRESS=DEFLATE'],\n",
        "                check=True,\n",
        "                capture_output=True,\n",
        "                text=True\n",
        "            )\n",
        "            print(f\"GDAL output: {result.stdout}\")\n",
        "            print(f\"GDAL errors: {result.stderr}\")\n",
        "\n",
        "            # Append the COG file path to the list\n",
        "            cog_file_paths.append(cog_output_file)\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error converting {tiff_file}: {e.stderr}\")\n",
        "\n",
        "    print(\"COG TIFF files generated and saved successfully.\")\n",
        "\n",
        "    return cog_file_paths\n",
        "\n",
        "# Step 3: Convert the TIFF files to COG TIFF\n",
        "cog_tiff_files = tiff_to_cogtiff(tiff_files)\n",
        "\n",
        "# Print TIFF files to verify\n",
        "print(\"Cloud Optimized GeoTIFFs files generated:\", cog_tiff_files)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "gdalENV",
      "language": "python",
      "name": "gdalenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}